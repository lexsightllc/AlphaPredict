# AlphaPredict: Hull Tactical Market Prediction Pipeline

An opinionated end-to-end machine learning stack built to compete in Kaggle's [Hull Tactical Market Prediction](https://www.kaggle.com/competitions/hull-tactical-market-prediction) challenge. The system targets daily excess returns of the S&P 500 index using a curated blend of financial and macroeconomic indicators while respecting the competition's strict real-time inference and data leakage requirements.

This repository serves as both the production code base and the accompanying research narrative. It is intentionally organized to balance experiment agility with the reproducibility demands of a regulated trading workflow.

## ğŸ“š Documentation Highlights

The primary documentation lives in [`README.md`](README.md) and the rendered research manuscript [`reports/final_report.md`](reports/final_report.md). The README motivates the tactical allocation problem, revisits the Efficient Market Hypothesis, and discusses how disciplined feature engineering and validation can expose exploitable market structure under realistic volatility constraints.

## ğŸ—‚ï¸ Project Layout

```
project_root/
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ External/
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â””â”€â”€ test.csv
â”‚   â””â”€â”€ Processed/
â”‚       â”œâ”€â”€ cleaned_train.parquet
â”‚       â””â”€â”€ feature_matrix.parquet
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda.ipynb
â”‚   â”œâ”€â”€ model_development.ipynb
â”‚   â””â”€â”€ api_submission_template.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ strategy.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ serving.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ final_report.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ backtest.py
â”‚   â””â”€â”€ api_stress_test.py
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ models/final_model.pkl
â”‚   â”œâ”€â”€ scalers/trained_scaler.pkl
â”‚   â””â”€â”€ metadata/
â”‚       â”œâ”€â”€ feature_list.json
â”‚       â””â”€â”€ training_statistics.json
â””â”€â”€ config/settings.yaml
```

> **Note:** Raw datasets and trained artifacts are excluded from version control. Populate the placeholders above by downloading Kaggle competition data or restoring artifacts from your secure storage.

## ğŸ”§ Core Modules

- **`src/config.py`** â€“ Centralized configuration definitions. Exposes strongly typed data classes for file system paths, preprocessing parameters, validation schedules, and model hyperparameters. Utility helpers load YAML configurations from [`config/settings.yaml`](config/settings.yaml).
- **`src/data_loader.py`** â€“ Data access layer that loads training and inference datasets, enforces schemas, and constructs time-aware cross-validation folds.
- **`src/preprocessing.py`** â€“ Full preprocessing pipeline: missing value handling, winsorization, lag creation, rolling statistics, alignment to the competition's latency window, and feature scaling.
- **`src/models.py`** â€“ Model abstractions unifying gradient boosted trees, regularized linear models, deep tabular networks, and ensemble stacks under a shared `fit`/`predict` interface.
- **`src/strategy.py`** â€“ Maps model predictions to valid position sizes in `[0, 2]` while honoring leverage caps, turnover throttles, and execution realism.
- **`src/evaluation.py`** â€“ Implements the competition-specific Sharpe metric with volatility penalties plus custom diagnostics such as drawdown, hit rate, and tail-risk exposure.
- **`src/serving.py`** â€“ Production inference surface compatible with the competition's real-time API. Ensures no forward-looking leakage, handles request batching, and streams predictions within latency constraints.
- **`src/utils.py`** â€“ Shared utilities including seed management, structured logging, configuration validation, and instrumentation helpers.

## ğŸ§ª Workflow Overview

1. **Data Preparation** â€“ Use `scripts/train.py` to load the external datasets, build lagged features with [`src/preprocessing.py`](src/preprocessing.py), and persist processed matrices to `data/Processed/`.
2. **Model Development** â€“ Experiment interactively inside [`notebooks/model_development.ipynb`](notebooks/model_development.ipynb). The notebook leverages the production preprocessing utilities to ensure parity between experiments and deployment.
3. **Training & Backtesting** â€“ Run `scripts/train.py` for production training. Validate robustness using `scripts/backtest.py`, which simulates execution frictions and drawdowns on out-of-sample periods.
4. **Serving** â€“ Package the trained model plus feature metadata into `artifacts/`. Use `scripts/api_stress_test.py` to assert that the [`src/serving.py`](src/serving.py) predict function satisfies latency limits under realistic loads.

## ğŸš€ Getting Started

```bash
# Create and activate environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .\.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Train and evaluate
python scripts/train.py
python scripts/backtest.py

# Launch local inference server
uvicorn src.serving:app --host 0.0.0.0 --port 8000
```

## ğŸ“ˆ Interpretability & Reporting

The pipeline logs experiment metadata and stores model explainability assets (feature importances, SHAP summaries, rolling Sharpe charts) under `reports/figures/`. The rendered [`reports/final_report.md`](reports/final_report.md) consolidates these insights into a narrative suitable for investment committees or compliance review.

## ğŸ¤ Contributing

1. Fork the repository and create a feature branch.
2. Run the formatting and linting checks defined in `pyproject.toml`.
3. Submit a pull request describing the motivation, methodology, and validation for your contribution.

## ğŸ“„ License

This project is released under the [Mozilla Public License 2.0](LICENSE). Please review the license before distributing derivative works.

## ğŸ“¬ Contact

Questions, bug reports, or collaboration requests are welcome via GitHub Issues.
